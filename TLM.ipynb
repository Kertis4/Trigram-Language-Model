{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501088c3-c5e8-4d0f-9a89-042196d7f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy          # used for safely copying lists and dictionaries\n",
    "import numpy as np   # used for generating elements from a list following a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267e082-4a81-4fa6-83a0-52d632182645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary object to count word frequencies\n",
    "word_frequencies = dict()\n",
    "with open('sentences_long.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        words = line.lower().split()\n",
    "        for word in words:\n",
    "            if word.isalpha():\n",
    "                word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ebe93-0324-44fa-af48-fc28fef07b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_word = max(word_frequencies, key=word_frequencies.get)\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "print(\"The most frequent word is \\'{}\\'\".format(most_frequent_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74d4b2-539c-4da3-96a3-b46aa4566ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_distribution = copy.deepcopy(word_frequencies)\n",
    "\n",
    "# ADD CODE HERE\n",
    "total_words = sum(word_distribution.values())\n",
    "for word in word_distribution:\n",
    "    word_distribution[word] /= total_words\n",
    "for word, prob in word_distribution.items():\n",
    "    print(\"The word \\'{}\\' has a probability of {:.10f}\".format(word, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc87a11-cc61-4a67-a407-d529db0b304f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(word_distribution\u001b[38;5;241m.\u001b[39mkeys()), \u001b[38;5;241m1\u001b[39m, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(word_distribution\u001b[38;5;241m.\u001b[39mvalues())))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#np random test\n",
    "list(np.random.choice(list(word_distribution.keys()), 1, p = list(word_distribution.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879c614-20dc-4c8a-ad41-dcd790da0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_words = word_distribution.keys()\n",
    "s_probs = word_distribution.values()\n",
    "\n",
    "generated_sentence = (np.random.choice((list(s_words)), 10, p = list(s_probs)))\n",
    "generated_sentence = ' '.join(generated_sentence)\n",
    "print(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8144d1d2-c276-487b-9ba2-6d6788965690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictiojnary object to count word frequencies\n",
    "bigram_frequencies = dict()\n",
    "with open('sentences_long.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        #print(\"Processing line:\", line)\n",
    "        words = line.lower().split()\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = words[i], words[i + 1]\n",
    "            bigram_frequencies[bigram] = bigram_frequencies.get(bigram, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5055e-e4dc-44b7-b1cd-6f0e4b47376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17206f-d503-4347-b99c-157f29c75eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_bigram = max(bigram_frequencies, key=bigram_frequencies.get)\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "print(\"The most frequent bigram is \\'{}\\'\".format(most_frequent_bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d047c-ec77-4585-bee8-c01bc650d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word = 'eat'\n",
    "most_frequent_follower = (first_word, max({pair: frequency for pair, frequency in bigram_frequencies.items() if pair[0] == first_word}.items(), key=lambda x: x[1])[0][1])\n",
    "\n",
    "\n",
    "# ADD CODE HERE\n",
    "\n",
    "print(\"The most frequent word to follow \\'{}\\' is \\'{}\\'\".format(first_word, most_frequent_follower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276ef7c-acc1-475a-8042-4297ec17645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary object to count word frequencies\n",
    "conditional_frequencies = dict()\n",
    "with open('sentences_long.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        words = line.lower().split()\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        for i in range(len(words) - 1):\n",
    "            word1 = words[i]\n",
    "            word2 = words[i + 1]\n",
    "            conditional_frequencies[word1] = conditional_frequencies.get(word1, dict())\n",
    "            conditional_frequencies[word1][word2] = conditional_frequencies[word1].get(word2, 0) + 1\n",
    "print({k: conditional_frequencies[k] for k in list(conditional_frequencies.keys())[:3]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d872a-244e-4d39-af79-66a78f09bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_frequencies['eat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1feca0b-cf5b-4e03-a2db-80f46726fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_distribution = copy.deepcopy(conditional_frequencies)\n",
    "\n",
    "for word1, following_words in conditional_distribution.items():\n",
    "    total_count = sum(following_words.values())\n",
    "    for word2 in following_words:\n",
    "        following_words[word2] = following_words[word2] / total_count\n",
    "print({k: conditional_distribution[k] for k in list(conditional_distribution.keys())[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec75b05-aea0-435b-9909-3cc29b8d8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word = 'eat'\n",
    "\n",
    "conditional_follower = (np.random.choice((list(conditional_frequencies[first_word])), 1, p = list(conditional_distribution[first_word].values()))[0])\n",
    "print(conditional_follower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c815e-8ecc-42ad-b7ba-8431c45b2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>']\n",
    "\n",
    "word_1 = 'aardvark'\n",
    "sentence.append(word_1)\n",
    "\n",
    "# ADD CODE HERE\n",
    "def generate_sentence(word_1, conditional_frequencies, conditional_distribution, max_length=15):\n",
    "    for x in range(max_length - 1):\n",
    "        if word_1 not in conditional_frequencies:\n",
    "            break\n",
    "        word_2 = np.random.choice(\n",
    "            list(conditional_frequencies[word_1]),\n",
    "            p=list(conditional_distribution[word_1].values())\n",
    "        )\n",
    "        sentence.append(word_2)\n",
    "        word_1 = word_2\n",
    "        \n",
    "    return sentence\n",
    "\n",
    "sentence = generate_sentence(word_1, conditional_frequencies, conditional_distribution, 15)\n",
    "sentence.append('</s>')\n",
    "sentence = ' '.join(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb10442-f138-438f-a5cc-0e591fccf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictiojnary object to count word frequencies\n",
    "conditional_frequencies_trigram = dict()\n",
    "\n",
    "with open('sentences_long.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        words = line.lower().split()\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        for i in range(len(words) - 2):\n",
    "            word1 = words[i]\n",
    "            word2 = words[i + 1]\n",
    "            word3 = words[i + 2]\n",
    "            \n",
    "            bigram = (word1, word2)\n",
    "            if bigram not in conditional_frequencies_trigram:\n",
    "                conditional_frequencies_trigram[bigram] = dict()\n",
    "            \n",
    "            conditional_frequencies_trigram[bigram][word3] = conditional_frequencies_trigram[bigram].get(word3, 0) + 1\n",
    "print({k: conditional_frequencies_trigram[k] for k in list(conditional_frequencies_trigram.keys())[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb08fa-cd82-4ca6-ab5a-b27449201b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_distribution_trigram = copy.deepcopy(conditional_frequencies_trigram)\n",
    "\n",
    "for bigram, following_words in conditional_frequencies_trigram.items():\n",
    "    total_count = sum(following_words.values())\n",
    "    for word, count in following_words.items():\n",
    "        following_words[word] = count / total_count\n",
    "\n",
    "print({k: conditional_frequencies_trigram[k] for k in list(conditional_frequencies_trigram.keys())[:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a460b79-dc2a-465a-b5cd-18530c15f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['<s>']\n",
    "\n",
    "word1 = 'aliens'\n",
    "sentence.append(word1)\n",
    "\n",
    "def normalize_probs(probs):\n",
    "    \"\"\" Ensure probabilities sum to 1 by normalizing \"\"\"\n",
    "    total = sum(probs)\n",
    "    return [p / total for p in probs] if total > 0 else probs  \n",
    "\n",
    "def generate_sentence_trigram(word1, conditional_frequencies, conditional_distribution, conditional_frequencies_trigram, conditional_distribution_trigram, max_length=30):\n",
    "    for _ in range(max_length - 2):  \n",
    "        if word1 not in conditional_frequencies:\n",
    "            break\n",
    "        choices_word2 = list(conditional_frequencies[word1])\n",
    "        probs_word2 = normalize_probs(list(conditional_distribution[word1].values()))\n",
    "        word2 = np.random.choice(choices_word2, p=probs_word2)\n",
    "        if (word1, word2) not in conditional_frequencies_trigram:\n",
    "            break\n",
    "        \n",
    "        choices_word3 = list(conditional_frequencies_trigram[word1, word2])\n",
    "        probs_word3 = normalize_probs(list(conditional_distribution_trigram[word1, word2].values()))\n",
    "        \n",
    "        word3 = np.random.choice(choices_word3, p=probs_word3)\n",
    "        sentence.append(word2)\n",
    "        sentence.append(word3)\n",
    "\n",
    "        word1 = word3  \n",
    "    \n",
    "    return sentence\n",
    "\n",
    "sentence = generate_sentence_trigram(word1, conditional_frequencies, conditional_distribution, conditional_frequencies_trigram, conditional_distribution_trigram, 30)\n",
    "sentence.append('</s>')\n",
    "sentence = ' '.join(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3541699e-0203-415e-a159-fb4159d9d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not work\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class Trigram_Language_Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conditional_distribution_bigram = {}\n",
    "        self.conditional_distribution_trigram = {}\n",
    "        self.conditional_frequencies_bigram = {}\n",
    "        self.conditional_frequencies_trigram = {}\n",
    "    \n",
    "    def train(self, corpus_file_name):\n",
    "       \n",
    "        unigram_freq = defaultdict(int)\n",
    "        bigram_freq = defaultdict(int)\n",
    "        trigram_freq = defaultdict(int)\n",
    "\n",
    "        \n",
    "        with open(corpus_file_name, 'r') as file:\n",
    "            sentences = file.readlines()\n",
    "\n",
    "       \n",
    "        for sentence in sentences:\n",
    "            words = sentence.strip().split()\n",
    "            words = ['<s>'] + words + ['</s>']\n",
    "\n",
    "            for i in range(len(words) - 1):\n",
    "                unigram_freq[words[i]] += 1\n",
    "                bigram_freq[(words[i], words[i+1])] += 1\n",
    "\n",
    "                if i < len(words) - 2:\n",
    "                    trigram_freq[(words[i], words[i+1], words[i+2])] += 1\n",
    "\n",
    "        \n",
    "        self.conditional_frequencies_bigram = bigram_freq\n",
    "        self.conditional_frequencies_trigram = trigram_freq\n",
    "        \n",
    "        self.conditional_distribution_bigram = defaultdict(dict)\n",
    "        self.conditional_distribution_trigram = defaultdict(dict)\n",
    "\n",
    "        \n",
    "        for (word1, word2), count in bigram_freq.items():\n",
    "            total_word1_count = sum(count for (w1, w2) in bigram_freq if w1 == word1)\n",
    "            self.conditional_distribution_bigram[word1][word2] = count / total_word1_count\n",
    "\n",
    "        \n",
    "        for (word1, word2, word3), count in trigram_freq.items():\n",
    "            total_bigram_count = sum(count for (w1, w2, w3) in trigram_freq if w1 == word1 and w2 == word2)\n",
    "            self.conditional_distribution_trigram[(word1, word2)][word3] = count / total_bigram_count\n",
    "\n",
    "    def generate_sentence(self, start_word, max_length=15):\n",
    "        sentence = ['<s>', start_word]\n",
    "        word1 = start_word\n",
    "\n",
    "        for _ in range(max_length - 2):  \n",
    "            if word1 not in self.conditional_distribution_bigram:\n",
    "                break\n",
    "\n",
    "            word2 = np.random.choice(\n",
    "                list(self.conditional_distribution_bigram[word1].keys()),\n",
    "                p=list(self.conditional_distribution_bigram[word1].values())\n",
    "            )\n",
    "\n",
    "            if (word1, word2) not in self.conditional_distribution_trigram:\n",
    "                break\n",
    "\n",
    "            word3 = np.random.choice(\n",
    "                list(self.conditional_distribution_trigram[(word1, word2)].keys()),\n",
    "                p=list(self.conditional_distribution_trigram[(word1, word2)].values())\n",
    "            )\n",
    "\n",
    "            sentence.append(word2)\n",
    "            sentence.append(word3)\n",
    "            word1 = word3\n",
    "\n",
    "        sentence.append('</s>')\n",
    "        return \" \".join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74154231-5abd-4bb2-bff4-410b23341358",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = Trigram_Language_Model()\n",
    "lm.train('sentences_long.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f50e44-188d-4093-adb8-cf37533f0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sentence_1 = lm.generate_sentence('aliens')\n",
    "print(generated_sentence_1)\n",
    "generated_sentence_2 = lm.generate_sentence('eat')\n",
    "print(generated_sentence_2)\n",
    "generated_sentence_3 = lm.generate_sentence('aardvark')\n",
    "print(generated_sentence_3)\n",
    "generated_sentence_4 = lm.generate_sentence('the')\n",
    "print(generated_sentence_4)\n",
    "generated_sentence_5 = lm.generate_sentence('eat')\n",
    "print(generated_sentence_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
